apiVersion: apps/v1
kind: Deployment
metadata:
  name: stable-diffusion
  namespace: ollama
  labels:
    app: stable-diffusion
spec:
  replicas: 1
  selector:
    matchLabels:
      app: stable-diffusion
  template:
    metadata:
      labels:
        app: stable-diffusion
    spec:
      containers:
        - name: automatic1111-container
          image: siutin/stable-diffusion-webui-docker:latest-cuda-12.1.1
          command:
            - bash
          args:
            - webui.sh
            - --share
          ports:
            - containerPort: 7860
          resources:
            requests:
              nvidia.com/gpu: 1
              memory: "32Gi"
              cpu: "4"
            limits:
              memory: "32Gi"
              cpu: "4"
              nvidia.com/gpu: 1
          volumeMounts:
            - name: models-volume
              mountPath: /app/stable-diffusion-webui/models
            - name: outputs-volume
              mountPath: /app/stable-diffusion-webui/outputs
      volumes:
        - name: models-volume
          persistentVolumeClaim:
            claimName: stable-diffusion-model-store
        - name: outputs-volume
          persistentVolumeClaim:
            claimName: stable-diffusion-model-output
      nodeSelector:
        nvidia.com/gpu.present: "true"
