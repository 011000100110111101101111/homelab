apiVersion: apps/v1
kind: Deployment
metadata:
  name: stable-diffusion
  namespace: ollama
  labels:
    app: stable-diffusion
spec:
  replicas: 1
  selector:
    matchLabels:
      app: stable-diffusion
  template:
    metadata:
      labels:
        app: stable-diffusion
    spec:
      containers:
        - name: automatic1111-container
          image: ghcr.io/ai-dock/stable-diffusion-webui:latest
          ports:
            - containerPort: 7860
          resources:
            requests:
              nvidia.com/gpu: 1
              memory: "32Gi"
              cpu: "4"
            limits:
              memory: "32Gi"
              cpu: "4"
              nvidia.com/gpu: 1
          env:
            - name: WEB_ENABLE_AUTH
              value: "false"
            - name: PORT
              value: "7860"
            - name: WEBUI_ARGS
              value: "--api --listen"
          volumeMounts:
            - name: models-volume
              mountPath: /opt/stable-diffusion-webui/models
      volumes:
        - name: models-volume
          persistentVolumeClaim:
            claimName: stable-diffusion-model-store
      nodeSelector:
        nvidia.com/gpu.present: "true"
